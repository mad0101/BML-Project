{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###1. Import the Libraries"
      ],
      "metadata": {
        "id": "y5C9pcOscn2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfLBXx3Qn_m-",
        "outputId": "9b7c7923-41dd-47c2-ab47-2509264de1a4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations_with_replacement\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from copy import deepcopy\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "zxPJT8Uvcr4C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Helper Functions -\n",
        "\n",
        "\n",
        "*   Class Combinations\n",
        "*   H ( Entropy )\n",
        "*   hasnan\n",
        "*   remove_occurences_from_list\n",
        "*   move_data\n",
        "\n"
      ],
      "metadata": {
        "id": "z0LHvF7bcu7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def class_combinations(c, n, m=np.inf):\n",
        "    \"\"\" Generates an array of n-element combinations where each element is one of\n",
        "    the c classes (an integer). If m is provided and m < n^c, then instead of all\n",
        "    n^c combinations, m combinations are randomly sampled.\n",
        "\n",
        "    Arguments:\n",
        "        c {int} -- the number of classes\n",
        "        n {int} -- the number of elements in each combination\n",
        "\n",
        "    Keyword Arguments:\n",
        "        m {int} -- the number of desired combinations (default: {np.inf})\n",
        "\n",
        "    Returns:\n",
        "        np.ndarry -- An [m x n] or [n^c x n] array of integers in [0, c)\n",
        "    \"\"\"\n",
        "\n",
        "    if m < c**n:\n",
        "        # randomly sample combinations\n",
        "        return np.random.randint(c, size=(int(m), n))\n",
        "    else:\n",
        "        p_c = combinations_with_replacement(np.arange(c), n)\n",
        "        result_array = np.array(list(iter(p_c)), dtype=int)\n",
        "        return result_array\n",
        "\n",
        "def H(x, eps=1e-6):\n",
        "    \"\"\" Compute the element-wise entropy of x\n",
        "\n",
        "    Arguments:\n",
        "        x {torch.Tensor} -- array of probabilities in (0,1)\n",
        "\n",
        "    Keyword Arguments:\n",
        "        eps {float} -- prevent failure on x == 0\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor -- H(x)\n",
        "    \"\"\"\n",
        "    return -(x+eps)*torch.log(x+eps)\n",
        "\n",
        "def hasnan(x):\n",
        "    return torch.isnan(x).any()\n",
        "\n",
        "def remove_occurrences_from_list(l, items):\n",
        "    # print(items)\n",
        "    return list(np.setdiff1d(np.array(l, dtype=int),\n",
        "        np.array(items, dtype=int), assume_unique=True))\n",
        "\n",
        "def move_data(indices, from_subset, to_subset):\n",
        "    from_subset.indices = remove_occurrences_from_list(from_subset.indices, indices)\n",
        "    if isinstance(to_subset.indices, list):\n",
        "        to_subset.indices.extend(indices)\n",
        "    elif isinstance(to_subset.indices, np.ndarray):\n",
        "        to_subset.indices = np.concatenate([to_subset.indices, np.array(indices)])"
      ],
      "metadata": {
        "id": "0-oPLeVCcGT4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Acquisition Functions"
      ],
      "metadata": {
        "id": "1RT3ymdseWIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base class for acquisition function.\n",
        "class Acquirer:\n",
        "    def __init__(self, batch_size, device):\n",
        "        self.batch_size = batch_size\n",
        "        self.processing_batch_size = 128\n",
        "        self.device = device\n",
        "\n",
        "    @staticmethod\n",
        "    def score(model, x):\n",
        "        \"\"\" Parallezied acquisition scoring function\n",
        "\n",
        "        Arguments:\n",
        "            model {nn.Module} -- the NN\n",
        "            x {torch.Tensor} -- datapoints to evaluate\n",
        "\n",
        "        Returns:\n",
        "            [torch.Tensor] -- a vector of acquisition scores\n",
        "        \"\"\"\n",
        "        return torch.zeros(len(x))\n",
        "\n",
        "\n",
        "    def select_batch(self, model, pool_data):\n",
        "        # score every datapoint in the pool under the model\n",
        "        pool_loader = torch.utils.data.DataLoader(pool_data,batch_size=self.processing_batch_size, pin_memory=True, shuffle=False)\n",
        "        scores = torch.zeros(len(pool_data)).to(self.device)\n",
        "        for batch_idx, (data, _) in enumerate(pool_loader):\n",
        "            end_idx = batch_idx + data.shape[0]\n",
        "            scores[batch_idx:end_idx] = self.score(model, data.to(self.device))\n",
        "\n",
        "        best_local_indices = torch.argsort(scores)[-self.batch_size:]\n",
        "        best_global_indices = np.array(pool_data.indices)[best_local_indices.cpu().numpy()]\n",
        "        return best_global_indices"
      ],
      "metadata": {
        "id": "vgEOgooCedIC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GgKX3BfgbX6m"
      },
      "outputs": [],
      "source": [
        "class Random(Acquirer):\n",
        "    def __init__(self, pool_data, device):\n",
        "        super(Random, self).__init__(pool_data, device)\n",
        "\n",
        "    @staticmethod\n",
        "    def score(model, _):\n",
        "        return np.random.rand()\n",
        "\n",
        "class MaxEntropy(Acquirer):\n",
        "    def __init__(self, batch_size, device):\n",
        "        super(MaxEntropy, self).__init__(batch_size, device)\n",
        "\n",
        "    def score(self, model, x):\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            outputs = model(x.to(self.device))\n",
        "            entropy = -torch.sum(outputs * torch.log(outputs + 1e-10), dim=1)\n",
        "        return entropy\n",
        "\n",
        "class VariationRatios(Acquirer):\n",
        "    def __init__(self, batch_size, device):\n",
        "        super(VariationRatios, self).__init__(batch_size, device)\n",
        "\n",
        "    def score(self, model, x):\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            outputs = torch.stack([model(x.to(self.device)) for _ in range(10)], dim=2)\n",
        "            mean_outputs = outputs.mean(dim=2)\n",
        "            variation_ratios = (outputs - mean_outputs.unsqueeze(2)).pow(2).mean(dim=2).sum(dim=1)\n",
        "        return variation_ratios\n",
        "\n",
        "class BALD(Acquirer):\n",
        "    def __init__(self, pool_data, device):\n",
        "        super(BALD, self).__init__(pool_data, device)\n",
        "\n",
        "    @staticmethod\n",
        "    def score(model, x, k=100):\n",
        "        # I(y;W | x) = H1 - H2 = H(y|x) - E_w[H(y|x,W)]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # take k monte-carlo samples of forward pass w/ dropout\n",
        "            Y = torch.stack([model(x) for i in range(k)], dim=1)\n",
        "            H1 = H(Y.mean(axis=1)).sum(axis=1)\n",
        "            H2 = H(Y).sum(axis=(1,2))/k\n",
        "\n",
        "            return H1 - H2\n",
        "\n",
        "\n",
        "class BatchBALD(Acquirer):\n",
        "    def __init__(self, pool_data, device):\n",
        "        super(BatchBALD, self).__init__(pool_data, device)\n",
        "        self.m = 1e4  # number of MC samples for label combinations\n",
        "        self.num_sub_pool = 500  # number of datapoints in the subpool from which we acquire\n",
        "\n",
        "    def select_batch(self, model, pool_data, k=100):\n",
        "        # I(y;W | x) = H1 - H2 = H(y|x) - E_w[H(y|x,W)]\n",
        "\n",
        "        c = 10 # number of classes\n",
        "\n",
        "        # performing BatchBALD on the whole pool is very expensive, so we take\n",
        "        # a random subset of the pool.\n",
        "        num_extra = len(pool_data) - self.num_sub_pool\n",
        "        if num_extra > 0:\n",
        "            sub_pool_data, _ = torch.utils.data.random_split(pool_data, [self.num_sub_pool, num_extra])\n",
        "        else:\n",
        "            # even if we don't have enough data left to split, we still need to\n",
        "            # call random_splot to avoid messing up the indexing later on\n",
        "            sub_pool_data, _ = torch.utils.data.random_split(pool_data, [len(pool_data), 0])\n",
        "\n",
        "         # forward pass on the pool once to get class probabilities for each x\n",
        "        with torch.no_grad():\n",
        "            pool_loader = torch.utils.data.DataLoader(sub_pool_data,\n",
        "                batch_size=self.processing_batch_size, pin_memory=True, shuffle=False)\n",
        "            pool_p_y = torch.zeros(len(sub_pool_data), c, k)\n",
        "            for batch_idx, (data, _) in enumerate(pool_loader):\n",
        "                end_idx = batch_idx + data.shape[0]\n",
        "                pool_p_y[batch_idx:end_idx] = torch.stack([model(data.to(self.device)) for i in range(k)], dim=1).permute(0,2,1)\n",
        "\n",
        "        # this only need to be calculated once so we pull it out of the loop\n",
        "        H2 = (H(pool_p_y).sum(axis=(1,2))/k).to(self.device)\n",
        "\n",
        "        # get all class combinations\n",
        "        c_1_to_n = class_combinations(c, self.batch_size, self.m)\n",
        "\n",
        "        # tensor of size [m x k]\n",
        "        p_y_1_to_n_minus_1 = None\n",
        "\n",
        "        # store the indices of the chosen datapoints in the subpool\n",
        "        best_sub_local_indices = []\n",
        "        # create a mask to keep track of which indices we've chosen\n",
        "        remaining_indices = torch.ones(len(sub_pool_data), dtype=bool).to(self.device)\n",
        "        for n in range(self.batch_size):\n",
        "            # tensor of size [N x m x l]\n",
        "            p_y_n = pool_p_y[:, c_1_to_n[:, n], :].to(self.device)\n",
        "            # tensor of size [N x m x k]\n",
        "            p_y_1_to_n = torch.einsum('mk,pmk->pmk', p_y_1_to_n_minus_1, p_y_n)\\\n",
        "                if p_y_1_to_n_minus_1 is not None else p_y_n\n",
        "\n",
        "            # and compute the left entropy term\n",
        "            H1 = H(p_y_1_to_n.mean(axis=2)).sum(axis=1)\n",
        "            # scores is a vector of scores for each element in the pool.\n",
        "            # mask by the remaining indices and find the highest scoring element\n",
        "            scores = H1 - H2\n",
        "            # print(scores)\n",
        "            best_local_index = torch.argmax(scores - np.inf*(~remaining_indices)).item()\n",
        "            # print(f'Best idx {best_local_index}')\n",
        "            best_sub_local_indices.append(best_local_index)\n",
        "            # save the computation for the next batch\n",
        "            p_y_1_to_n_minus_1 = p_y_1_to_n[best_local_index]\n",
        "            # remove the chosen element from the remaining indices mask\n",
        "            remaining_indices[best_local_index] = False\n",
        "\n",
        "        # we've subset-ed our dataset twice, so we need to go back through\n",
        "        # subset indices twice to recover the global indices of the chosen data\n",
        "        best_local_indices = np.array(sub_pool_data.indices)[best_sub_local_indices]\n",
        "        best_global_indices = np.array(pool_data.indices)[best_local_indices]\n",
        "        return best_global_indices"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "acquisition_batch_size = 64\n",
        "train_batch_size = 64\n",
        "num_train = 5000\n",
        "# Change the initial pool size here. ( GOAL -  Shorten the overall cycle for Active Learning)\n",
        "num_pool = 1000\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(784, 2048),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 128),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10))\n",
        "\n",
        "\n",
        "    def forward(self, x, return_logits=False):\n",
        "        x = torch.flatten(x, 1)\n",
        "        logits = self.layers(x)\n",
        "        if return_logits:\n",
        "            return logits\n",
        "        else:\n",
        "            return F.softmax(logits, 1)\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    print('Training the Model on new Training Set')\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data, return_logits=True)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Epoch : {} [{}/{} ({:.0f}%)]\\n Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "        epoch  = epoch + 1\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data, return_logits=True)\n",
        "            #outputs = model(data)\n",
        "            #predictions.append(outputs.cpu().numpy())\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    print('Testing the Model on Test Set \\n')\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = float(correct) / len(test_loader.dataset)\n",
        "    print('Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * accuracy))\n",
        "\n",
        "    return accuracy,test_loss\n",
        "\n",
        "def active(model, acquirer, device, data, optimizer):\n",
        "    train_data, pool_data, test_data = data\n",
        "\n",
        "    test_losses = []\n",
        "    test_accuracies = []\n",
        "    un_test_acc_lst = []\n",
        "    un_test_pred_lst = []\n",
        "    while len(pool_data) > 0:\n",
        "        print(f'Using {acquirer.__class__.__name__} Acquiring technique for Batch Acquisition.\\n Current size of the Pool Set: {len(pool_data)}')\n",
        "        # get the indices of the best batch of data\n",
        "        batch_indices = acquirer.select_batch(model, pool_data)\n",
        "        # move that data from the pool to the training set\n",
        "        move_data(batch_indices, pool_data, train_data)\n",
        "        # train on it\n",
        "        train_loader = torch.utils.data.DataLoader(train_data,\n",
        "            batch_size = train_batch_size, pin_memory=True, shuffle=True)\n",
        "        train(model, device, train_loader, optimizer, 0)\n",
        "\n",
        "        # test the accuracy\n",
        "        test_loader = torch.utils.data.DataLoader(test_data,\n",
        "            batch_size = train_batch_size, pin_memory=True, shuffle=True)\n",
        "        test_acc, test_loss = test(model, device, test_loader)\n",
        "        test_accuracies.append(test_acc)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "    return test_accuracies,test_losses"
      ],
      "metadata": {
        "id": "5qgUytKsbuj0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "Secw8BOm_htw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # set up the GPU if one exists\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    # load the dataset and pre-process\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "    dataset = datasets.MNIST('data', train=True, download=True,\n",
        "                       transform=transform)\n",
        "\n",
        "    subset_indices = np.random.choice(len(dataset), size=num_train+num_pool, replace=False)\n",
        "    train_indices = subset_indices[:num_train]\n",
        "    pool_indices = subset_indices[-num_pool:]\n",
        "    train_data = train_data = torch.utils.data.Subset(dataset, train_indices)\n",
        "    test_data = datasets.MNIST('data', train=False,\n",
        "                       transform=transform)\n",
        "    pretrain_loader = torch.utils.data.DataLoader(train_data,\n",
        "        batch_size=train_batch_size, pin_memory=True, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data,\n",
        "        batch_size=train_batch_size, pin_memory=True, shuffle=True)\n",
        "\n",
        "    # init the model and optimizer\n",
        "    model = Net().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    #Train the model and test after each epoch\n",
        "    for epoch in range(1, 2):\n",
        "        train(model, device, pretrain_loader, optimizer, epoch)\n",
        "        test(model, device, test_loader)\\\n",
        "\n",
        "    pre_acquisition_model_state = model.state_dict()\n",
        "\n",
        "    #for acquisition_strategy in [Random, BALD, BatchBALD]:\n",
        "    for acquisition_strategy in [Random, MaxEntropy, VariationRatios,BALD, BatchBALD]:\n",
        "    #for acquisition_strategy in [Random,MaxEntropy]:\n",
        "        # reset the model\n",
        "        model.load_state_dict(deepcopy(pre_acquisition_model_state))\n",
        "        # init the acquirer\n",
        "        acquirer = acquisition_strategy(acquisition_batch_size, device)\n",
        "        # and an optimizer\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "        # get all the data\n",
        "        train_data = torch.utils.data.Subset(dataset, train_indices)\n",
        "        pool_data = torch.utils.data.Subset(dataset, pool_indices)\n",
        "        data = (train_data, pool_data, test_data)\n",
        "        # train the model with active learning\n",
        "        accuracies,losses = active(model, acquirer, device, data, optimizer)\n",
        "        # Test the model with uncertainty\n",
        "        torch.save(model.state_dict(), f'/content/drive/MyDrive/BML/model_{acquisition_strategy.__name__}.pth')\n",
        "        # Set Seaborn dark theme\n",
        "        sns.set_theme(style=\"darkgrid\")\n",
        "        sns.lineplot(x=range(len(accuracies)), y=accuracies, label=acquisition_strategy.__name__)\n",
        "        # Plot accuracy with uncertainty\n",
        "\n",
        "    plt.title('Comparison of Distinct Acquisition Functions for Active Learning')\n",
        "    plt.xlabel('Iterations (No. of Batch Pool Acquisitions)')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I--__Yt4cTlx",
        "outputId": "4cdb0d1c-05e4-4d95-b418-8c9b829a3830"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the Model on new Training Set\n",
            "Epoch : 1 [0/5000 (0%)]\n",
            " Loss: 2.315302\n",
            "Epoch : 11 [640/5000 (13%)]\n",
            " Loss: 1.367876\n",
            "Epoch : 21 [1280/5000 (25%)]\n",
            " Loss: 1.205094\n",
            "Epoch : 31 [1920/5000 (38%)]\n",
            " Loss: 0.703223\n",
            "Epoch : 41 [2560/5000 (51%)]\n",
            " Loss: 0.666639\n",
            "Epoch : 51 [3200/5000 (63%)]\n",
            " Loss: 0.371248\n",
            "Epoch : 61 [3840/5000 (76%)]\n",
            " Loss: 0.496089\n",
            "Epoch : 71 [4480/5000 (89%)]\n",
            " Loss: 0.852325\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3255, Accuracy: 8982/10000 (90%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 1000\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5064 (0%)]\n",
            " Loss: 0.283791\n",
            "Epoch : 10 [640/5064 (12%)]\n",
            " Loss: 0.400911\n",
            "Epoch : 20 [1280/5064 (25%)]\n",
            " Loss: 0.353293\n",
            "Epoch : 30 [1920/5064 (38%)]\n",
            " Loss: 0.593293\n",
            "Epoch : 40 [2560/5064 (50%)]\n",
            " Loss: 0.686321\n",
            "Epoch : 50 [3200/5064 (62%)]\n",
            " Loss: 0.475817\n",
            "Epoch : 60 [3840/5064 (75%)]\n",
            " Loss: 0.521977\n",
            "Epoch : 70 [4480/5064 (88%)]\n",
            " Loss: 0.354386\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2655, Accuracy: 9181/10000 (92%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 936\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5128 (0%)]\n",
            " Loss: 0.311884\n",
            "Epoch : 10 [640/5128 (12%)]\n",
            " Loss: 0.185956\n",
            "Epoch : 20 [1280/5128 (25%)]\n",
            " Loss: 0.286340\n",
            "Epoch : 30 [1920/5128 (37%)]\n",
            " Loss: 0.539874\n",
            "Epoch : 40 [2560/5128 (49%)]\n",
            " Loss: 0.304960\n",
            "Epoch : 50 [3200/5128 (62%)]\n",
            " Loss: 0.227311\n",
            "Epoch : 60 [3840/5128 (74%)]\n",
            " Loss: 0.316633\n",
            "Epoch : 70 [4480/5128 (86%)]\n",
            " Loss: 0.283787\n",
            "Epoch : 80 [640/5128 (99%)]\n",
            " Loss: 0.006136\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2103, Accuracy: 9351/10000 (94%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 872\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5192 (0%)]\n",
            " Loss: 0.174460\n",
            "Epoch : 10 [640/5192 (12%)]\n",
            " Loss: 0.322813\n",
            "Epoch : 20 [1280/5192 (24%)]\n",
            " Loss: 0.187295\n",
            "Epoch : 30 [1920/5192 (37%)]\n",
            " Loss: 0.232700\n",
            "Epoch : 40 [2560/5192 (49%)]\n",
            " Loss: 0.163171\n",
            "Epoch : 50 [3200/5192 (61%)]\n",
            " Loss: 0.174822\n",
            "Epoch : 60 [3840/5192 (73%)]\n",
            " Loss: 0.209689\n",
            "Epoch : 70 [4480/5192 (85%)]\n",
            " Loss: 0.142073\n",
            "Epoch : 80 [5120/5192 (98%)]\n",
            " Loss: 0.224211\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2151, Accuracy: 9333/10000 (93%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 808\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5256 (0%)]\n",
            " Loss: 0.218324\n",
            "Epoch : 10 [640/5256 (12%)]\n",
            " Loss: 0.197764\n",
            "Epoch : 20 [1280/5256 (24%)]\n",
            " Loss: 0.201381\n",
            "Epoch : 30 [1920/5256 (36%)]\n",
            " Loss: 0.081003\n",
            "Epoch : 40 [2560/5256 (48%)]\n",
            " Loss: 0.218784\n",
            "Epoch : 50 [3200/5256 (60%)]\n",
            " Loss: 0.393200\n",
            "Epoch : 60 [3840/5256 (72%)]\n",
            " Loss: 0.203852\n",
            "Epoch : 70 [4480/5256 (84%)]\n",
            " Loss: 0.339527\n",
            "Epoch : 80 [5120/5256 (96%)]\n",
            " Loss: 0.195838\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1790, Accuracy: 9443/10000 (94%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 744\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5320 (0%)]\n",
            " Loss: 0.122649\n",
            "Epoch : 10 [640/5320 (12%)]\n",
            " Loss: 0.200730\n",
            "Epoch : 20 [1280/5320 (24%)]\n",
            " Loss: 0.174450\n",
            "Epoch : 30 [1920/5320 (36%)]\n",
            " Loss: 0.151194\n",
            "Epoch : 40 [2560/5320 (48%)]\n",
            " Loss: 0.217740\n",
            "Epoch : 50 [3200/5320 (60%)]\n",
            " Loss: 0.212687\n",
            "Epoch : 60 [3840/5320 (71%)]\n",
            " Loss: 0.170061\n",
            "Epoch : 70 [4480/5320 (83%)]\n",
            " Loss: 0.163521\n",
            "Epoch : 80 [5120/5320 (95%)]\n",
            " Loss: 0.150423\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1696, Accuracy: 9485/10000 (95%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 680\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5384 (0%)]\n",
            " Loss: 0.067066\n",
            "Epoch : 10 [640/5384 (12%)]\n",
            " Loss: 0.127696\n",
            "Epoch : 20 [1280/5384 (24%)]\n",
            " Loss: 0.197496\n",
            "Epoch : 30 [1920/5384 (35%)]\n",
            " Loss: 0.286283\n",
            "Epoch : 40 [2560/5384 (47%)]\n",
            " Loss: 0.159556\n",
            "Epoch : 50 [3200/5384 (59%)]\n",
            " Loss: 0.106560\n",
            "Epoch : 60 [3840/5384 (71%)]\n",
            " Loss: 0.193288\n",
            "Epoch : 70 [4480/5384 (82%)]\n",
            " Loss: 0.215712\n",
            "Epoch : 80 [5120/5384 (94%)]\n",
            " Loss: 0.258630\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1794, Accuracy: 9463/10000 (95%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 616\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5448 (0%)]\n",
            " Loss: 0.049802\n",
            "Epoch : 10 [640/5448 (12%)]\n",
            " Loss: 0.082772\n",
            "Epoch : 20 [1280/5448 (23%)]\n",
            " Loss: 0.131906\n",
            "Epoch : 30 [1920/5448 (35%)]\n",
            " Loss: 0.116745\n",
            "Epoch : 40 [2560/5448 (47%)]\n",
            " Loss: 0.365745\n",
            "Epoch : 50 [3200/5448 (58%)]\n",
            " Loss: 0.083291\n",
            "Epoch : 60 [3840/5448 (70%)]\n",
            " Loss: 0.098450\n",
            "Epoch : 70 [4480/5448 (81%)]\n",
            " Loss: 0.034749\n",
            "Epoch : 80 [5120/5448 (93%)]\n",
            " Loss: 0.153290\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1753, Accuracy: 9496/10000 (95%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 552\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5512 (0%)]\n",
            " Loss: 0.039696\n",
            "Epoch : 10 [640/5512 (11%)]\n",
            " Loss: 0.064414\n",
            "Epoch : 20 [1280/5512 (23%)]\n",
            " Loss: 0.130728\n",
            "Epoch : 30 [1920/5512 (34%)]\n",
            " Loss: 0.179016\n",
            "Epoch : 40 [2560/5512 (46%)]\n",
            " Loss: 0.243368\n",
            "Epoch : 50 [3200/5512 (57%)]\n",
            " Loss: 0.149257\n",
            "Epoch : 60 [3840/5512 (69%)]\n",
            " Loss: 0.105831\n",
            "Epoch : 70 [4480/5512 (80%)]\n",
            " Loss: 0.109604\n",
            "Epoch : 80 [5120/5512 (92%)]\n",
            " Loss: 0.065249\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1843, Accuracy: 9509/10000 (95%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 488\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5576 (0%)]\n",
            " Loss: 0.051459\n",
            "Epoch : 10 [640/5576 (11%)]\n",
            " Loss: 0.145285\n",
            "Epoch : 20 [1280/5576 (23%)]\n",
            " Loss: 0.063088\n",
            "Epoch : 30 [1920/5576 (34%)]\n",
            " Loss: 0.230283\n",
            "Epoch : 40 [2560/5576 (45%)]\n",
            " Loss: 0.162780\n",
            "Epoch : 50 [3200/5576 (57%)]\n",
            " Loss: 0.055406\n",
            "Epoch : 60 [3840/5576 (68%)]\n",
            " Loss: 0.104845\n",
            "Epoch : 70 [4480/5576 (80%)]\n",
            " Loss: 0.026561\n",
            "Epoch : 80 [5120/5576 (91%)]\n",
            " Loss: 0.043057\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1715, Accuracy: 9502/10000 (95%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 424\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5640 (0%)]\n",
            " Loss: 0.037360\n",
            "Epoch : 10 [640/5640 (11%)]\n",
            " Loss: 0.226770\n",
            "Epoch : 20 [1280/5640 (22%)]\n",
            " Loss: 0.071321\n",
            "Epoch : 30 [1920/5640 (34%)]\n",
            " Loss: 0.143557\n",
            "Epoch : 40 [2560/5640 (45%)]\n",
            " Loss: 0.063551\n",
            "Epoch : 50 [3200/5640 (56%)]\n",
            " Loss: 0.022828\n",
            "Epoch : 60 [3840/5640 (67%)]\n",
            " Loss: 0.089305\n",
            "Epoch : 70 [4480/5640 (79%)]\n",
            " Loss: 0.125815\n",
            "Epoch : 80 [5120/5640 (90%)]\n",
            " Loss: 0.062660\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1771, Accuracy: 9532/10000 (95%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 360\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5704 (0%)]\n",
            " Loss: 0.011119\n",
            "Epoch : 10 [640/5704 (11%)]\n",
            " Loss: 0.051071\n",
            "Epoch : 20 [1280/5704 (22%)]\n",
            " Loss: 0.019520\n",
            "Epoch : 30 [1920/5704 (33%)]\n",
            " Loss: 0.062967\n",
            "Epoch : 40 [2560/5704 (44%)]\n",
            " Loss: 0.128179\n",
            "Epoch : 50 [3200/5704 (56%)]\n",
            " Loss: 0.049817\n",
            "Epoch : 60 [3840/5704 (67%)]\n",
            " Loss: 0.090292\n",
            "Epoch : 70 [4480/5704 (78%)]\n",
            " Loss: 0.098532\n",
            "Epoch : 80 [5120/5704 (89%)]\n",
            " Loss: 0.108208\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1765, Accuracy: 9525/10000 (95%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 296\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5768 (0%)]\n",
            " Loss: 0.034751\n",
            "Epoch : 10 [640/5768 (11%)]\n",
            " Loss: 0.043955\n",
            "Epoch : 20 [1280/5768 (22%)]\n",
            " Loss: 0.030128\n",
            "Epoch : 30 [1920/5768 (33%)]\n",
            " Loss: 0.052980\n",
            "Epoch : 40 [2560/5768 (44%)]\n",
            " Loss: 0.012260\n",
            "Epoch : 50 [3200/5768 (55%)]\n",
            " Loss: 0.054223\n",
            "Epoch : 60 [3840/5768 (66%)]\n",
            " Loss: 0.077529\n",
            "Epoch : 70 [4480/5768 (77%)]\n",
            " Loss: 0.116079\n",
            "Epoch : 80 [5120/5768 (88%)]\n",
            " Loss: 0.062337\n",
            "Epoch : 90 [720/5768 (99%)]\n",
            " Loss: 0.013186\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2296, Accuracy: 9420/10000 (94%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 232\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5832 (0%)]\n",
            " Loss: 0.062624\n",
            "Epoch : 10 [640/5832 (11%)]\n",
            " Loss: 0.063735\n",
            "Epoch : 20 [1280/5832 (22%)]\n",
            " Loss: 0.099068\n",
            "Epoch : 30 [1920/5832 (33%)]\n",
            " Loss: 0.071421\n",
            "Epoch : 40 [2560/5832 (43%)]\n",
            " Loss: 0.036193\n",
            "Epoch : 50 [3200/5832 (54%)]\n",
            " Loss: 0.107165\n",
            "Epoch : 60 [3840/5832 (65%)]\n",
            " Loss: 0.120087\n",
            "Epoch : 70 [4480/5832 (76%)]\n",
            " Loss: 0.103333\n",
            "Epoch : 80 [5120/5832 (87%)]\n",
            " Loss: 0.053270\n",
            "Epoch : 90 [5760/5832 (98%)]\n",
            " Loss: 0.083349\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1552, Accuracy: 9586/10000 (96%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 168\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5896 (0%)]\n",
            " Loss: 0.046526\n",
            "Epoch : 10 [640/5896 (11%)]\n",
            " Loss: 0.016077\n",
            "Epoch : 20 [1280/5896 (22%)]\n",
            " Loss: 0.018609\n",
            "Epoch : 30 [1920/5896 (32%)]\n",
            " Loss: 0.008551\n",
            "Epoch : 40 [2560/5896 (43%)]\n",
            " Loss: 0.089714\n",
            "Epoch : 50 [3200/5896 (54%)]\n",
            " Loss: 0.125053\n",
            "Epoch : 60 [3840/5896 (65%)]\n",
            " Loss: 0.065272\n",
            "Epoch : 70 [4480/5896 (75%)]\n",
            " Loss: 0.106921\n",
            "Epoch : 80 [5120/5896 (86%)]\n",
            " Loss: 0.027196\n",
            "Epoch : 90 [5760/5896 (97%)]\n",
            " Loss: 0.051471\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1761, Accuracy: 9557/10000 (96%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 104\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5960 (0%)]\n",
            " Loss: 0.016759\n",
            "Epoch : 10 [640/5960 (11%)]\n",
            " Loss: 0.131163\n",
            "Epoch : 20 [1280/5960 (21%)]\n",
            " Loss: 0.034095\n",
            "Epoch : 30 [1920/5960 (32%)]\n",
            " Loss: 0.247823\n",
            "Epoch : 40 [2560/5960 (43%)]\n",
            " Loss: 0.069425\n",
            "Epoch : 50 [3200/5960 (53%)]\n",
            " Loss: 0.006424\n",
            "Epoch : 60 [3840/5960 (64%)]\n",
            " Loss: 0.120235\n",
            "Epoch : 70 [4480/5960 (74%)]\n",
            " Loss: 0.095486\n",
            "Epoch : 80 [5120/5960 (85%)]\n",
            " Loss: 0.178463\n",
            "Epoch : 90 [5760/5960 (96%)]\n",
            " Loss: 0.060114\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1837, Accuracy: 9537/10000 (95%)\n",
            "\n",
            "Using Random Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 40\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/6000 (0%)]\n",
            " Loss: 0.085483\n",
            "Epoch : 10 [640/6000 (11%)]\n",
            " Loss: 0.066959\n",
            "Epoch : 20 [1280/6000 (21%)]\n",
            " Loss: 0.093576\n",
            "Epoch : 30 [1920/6000 (32%)]\n",
            " Loss: 0.086265\n",
            "Epoch : 40 [2560/6000 (43%)]\n",
            " Loss: 0.112463\n",
            "Epoch : 50 [3200/6000 (53%)]\n",
            " Loss: 0.008183\n",
            "Epoch : 60 [3840/6000 (64%)]\n",
            " Loss: 0.053440\n",
            "Epoch : 70 [4480/6000 (74%)]\n",
            " Loss: 0.161567\n",
            "Epoch : 80 [5120/6000 (85%)]\n",
            " Loss: 0.100296\n",
            "Epoch : 90 [5760/6000 (96%)]\n",
            " Loss: 0.168687\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1631, Accuracy: 9594/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 1000\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5064 (0%)]\n",
            " Loss: 0.050333\n",
            "Epoch : 10 [640/5064 (12%)]\n",
            " Loss: 0.006921\n",
            "Epoch : 20 [1280/5064 (25%)]\n",
            " Loss: 0.068124\n",
            "Epoch : 30 [1920/5064 (38%)]\n",
            " Loss: 0.052273\n",
            "Epoch : 40 [2560/5064 (50%)]\n",
            " Loss: 0.028939\n",
            "Epoch : 50 [3200/5064 (62%)]\n",
            " Loss: 0.229000\n",
            "Epoch : 60 [3840/5064 (75%)]\n",
            " Loss: 0.021436\n",
            "Epoch : 70 [4480/5064 (88%)]\n",
            " Loss: 0.011461\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2560, Accuracy: 9534/10000 (95%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 936\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5128 (0%)]\n",
            " Loss: 0.096700\n",
            "Epoch : 10 [640/5128 (12%)]\n",
            " Loss: 0.026522\n",
            "Epoch : 20 [1280/5128 (25%)]\n",
            " Loss: 0.061102\n",
            "Epoch : 30 [1920/5128 (37%)]\n",
            " Loss: 0.111320\n",
            "Epoch : 40 [2560/5128 (49%)]\n",
            " Loss: 0.037139\n",
            "Epoch : 50 [3200/5128 (62%)]\n",
            " Loss: 0.020752\n",
            "Epoch : 60 [3840/5128 (74%)]\n",
            " Loss: 0.041878\n",
            "Epoch : 70 [4480/5128 (86%)]\n",
            " Loss: 0.031865\n",
            "Epoch : 80 [640/5128 (99%)]\n",
            " Loss: 0.000009\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2200, Accuracy: 9572/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 872\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5192 (0%)]\n",
            " Loss: 0.030452\n",
            "Epoch : 10 [640/5192 (12%)]\n",
            " Loss: 0.003759\n",
            "Epoch : 20 [1280/5192 (24%)]\n",
            " Loss: 0.151862\n",
            "Epoch : 30 [1920/5192 (37%)]\n",
            " Loss: 0.018695\n",
            "Epoch : 40 [2560/5192 (49%)]\n",
            " Loss: 0.036074\n",
            "Epoch : 50 [3200/5192 (61%)]\n",
            " Loss: 0.078026\n",
            "Epoch : 60 [3840/5192 (73%)]\n",
            " Loss: 0.031277\n",
            "Epoch : 70 [4480/5192 (85%)]\n",
            " Loss: 0.027208\n",
            "Epoch : 80 [5120/5192 (98%)]\n",
            " Loss: 0.335502\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2258, Accuracy: 9550/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 808\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5256 (0%)]\n",
            " Loss: 0.018553\n",
            "Epoch : 10 [640/5256 (12%)]\n",
            " Loss: 0.028024\n",
            "Epoch : 20 [1280/5256 (24%)]\n",
            " Loss: 0.009231\n",
            "Epoch : 30 [1920/5256 (36%)]\n",
            " Loss: 0.064838\n",
            "Epoch : 40 [2560/5256 (48%)]\n",
            " Loss: 0.126343\n",
            "Epoch : 50 [3200/5256 (60%)]\n",
            " Loss: 0.015531\n",
            "Epoch : 60 [3840/5256 (72%)]\n",
            " Loss: 0.048993\n",
            "Epoch : 70 [4480/5256 (84%)]\n",
            " Loss: 0.121221\n",
            "Epoch : 80 [5120/5256 (96%)]\n",
            " Loss: 0.008079\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1989, Accuracy: 9567/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 744\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5320 (0%)]\n",
            " Loss: 0.010743\n",
            "Epoch : 10 [640/5320 (12%)]\n",
            " Loss: 0.025691\n",
            "Epoch : 20 [1280/5320 (24%)]\n",
            " Loss: 0.012947\n",
            "Epoch : 30 [1920/5320 (36%)]\n",
            " Loss: 0.068489\n",
            "Epoch : 40 [2560/5320 (48%)]\n",
            " Loss: 0.060806\n",
            "Epoch : 50 [3200/5320 (60%)]\n",
            " Loss: 0.023080\n",
            "Epoch : 60 [3840/5320 (71%)]\n",
            " Loss: 0.017356\n",
            "Epoch : 70 [4480/5320 (83%)]\n",
            " Loss: 0.246873\n",
            "Epoch : 80 [5120/5320 (95%)]\n",
            " Loss: 0.024388\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1888, Accuracy: 9597/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 680\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5384 (0%)]\n",
            " Loss: 0.045819\n",
            "Epoch : 10 [640/5384 (12%)]\n",
            " Loss: 0.037168\n",
            "Epoch : 20 [1280/5384 (24%)]\n",
            " Loss: 0.028166\n",
            "Epoch : 30 [1920/5384 (35%)]\n",
            " Loss: 0.058144\n",
            "Epoch : 40 [2560/5384 (47%)]\n",
            " Loss: 0.017957\n",
            "Epoch : 50 [3200/5384 (59%)]\n",
            " Loss: 0.011752\n",
            "Epoch : 60 [3840/5384 (71%)]\n",
            " Loss: 0.017157\n",
            "Epoch : 70 [4480/5384 (82%)]\n",
            " Loss: 0.187453\n",
            "Epoch : 80 [5120/5384 (94%)]\n",
            " Loss: 0.023268\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2103, Accuracy: 9588/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 616\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5448 (0%)]\n",
            " Loss: 0.104673\n",
            "Epoch : 10 [640/5448 (12%)]\n",
            " Loss: 0.069680\n",
            "Epoch : 20 [1280/5448 (23%)]\n",
            " Loss: 0.078643\n",
            "Epoch : 30 [1920/5448 (35%)]\n",
            " Loss: 0.049298\n",
            "Epoch : 40 [2560/5448 (47%)]\n",
            " Loss: 0.539316\n",
            "Epoch : 50 [3200/5448 (58%)]\n",
            " Loss: 0.045817\n",
            "Epoch : 60 [3840/5448 (70%)]\n",
            " Loss: 0.170528\n",
            "Epoch : 70 [4480/5448 (81%)]\n",
            " Loss: 0.081823\n",
            "Epoch : 80 [5120/5448 (93%)]\n",
            " Loss: 0.089759\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2165, Accuracy: 9569/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 552\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5512 (0%)]\n",
            " Loss: 0.031654\n",
            "Epoch : 10 [640/5512 (11%)]\n",
            " Loss: 0.028636\n",
            "Epoch : 20 [1280/5512 (23%)]\n",
            " Loss: 0.084145\n",
            "Epoch : 30 [1920/5512 (34%)]\n",
            " Loss: 0.094688\n",
            "Epoch : 40 [2560/5512 (46%)]\n",
            " Loss: 0.054826\n",
            "Epoch : 50 [3200/5512 (57%)]\n",
            " Loss: 0.101099\n",
            "Epoch : 60 [3840/5512 (69%)]\n",
            " Loss: 0.039179\n",
            "Epoch : 70 [4480/5512 (80%)]\n",
            " Loss: 0.018334\n",
            "Epoch : 80 [5120/5512 (92%)]\n",
            " Loss: 0.209842\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2085, Accuracy: 9573/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 488\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5576 (0%)]\n",
            " Loss: 0.080793\n",
            "Epoch : 10 [640/5576 (11%)]\n",
            " Loss: 0.084233\n",
            "Epoch : 20 [1280/5576 (23%)]\n",
            " Loss: 0.023100\n",
            "Epoch : 30 [1920/5576 (34%)]\n",
            " Loss: 0.012062\n",
            "Epoch : 40 [2560/5576 (45%)]\n",
            " Loss: 0.022406\n",
            "Epoch : 50 [3200/5576 (57%)]\n",
            " Loss: 0.050525\n",
            "Epoch : 60 [3840/5576 (68%)]\n",
            " Loss: 0.011024\n",
            "Epoch : 70 [4480/5576 (80%)]\n",
            " Loss: 0.009090\n",
            "Epoch : 80 [5120/5576 (91%)]\n",
            " Loss: 0.018916\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2274, Accuracy: 9529/10000 (95%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 424\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5640 (0%)]\n",
            " Loss: 0.014877\n",
            "Epoch : 10 [640/5640 (11%)]\n",
            " Loss: 0.157869\n",
            "Epoch : 20 [1280/5640 (22%)]\n",
            " Loss: 0.091201\n",
            "Epoch : 30 [1920/5640 (34%)]\n",
            " Loss: 0.007858\n",
            "Epoch : 40 [2560/5640 (45%)]\n",
            " Loss: 0.006993\n",
            "Epoch : 50 [3200/5640 (56%)]\n",
            " Loss: 0.213088\n",
            "Epoch : 60 [3840/5640 (67%)]\n",
            " Loss: 0.082488\n",
            "Epoch : 70 [4480/5640 (79%)]\n",
            " Loss: 0.023113\n",
            "Epoch : 80 [5120/5640 (90%)]\n",
            " Loss: 0.001405\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1918, Accuracy: 9605/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 360\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5704 (0%)]\n",
            " Loss: 0.012415\n",
            "Epoch : 10 [640/5704 (11%)]\n",
            " Loss: 0.036946\n",
            "Epoch : 20 [1280/5704 (22%)]\n",
            " Loss: 0.182669\n",
            "Epoch : 30 [1920/5704 (33%)]\n",
            " Loss: 0.017921\n",
            "Epoch : 40 [2560/5704 (44%)]\n",
            " Loss: 0.014040\n",
            "Epoch : 50 [3200/5704 (56%)]\n",
            " Loss: 0.015699\n",
            "Epoch : 60 [3840/5704 (67%)]\n",
            " Loss: 0.010000\n",
            "Epoch : 70 [4480/5704 (78%)]\n",
            " Loss: 0.007499\n",
            "Epoch : 80 [5120/5704 (89%)]\n",
            " Loss: 0.047179\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1944, Accuracy: 9589/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 296\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5768 (0%)]\n",
            " Loss: 0.005131\n",
            "Epoch : 10 [640/5768 (11%)]\n",
            " Loss: 0.003053\n",
            "Epoch : 20 [1280/5768 (22%)]\n",
            " Loss: 0.248623\n",
            "Epoch : 30 [1920/5768 (33%)]\n",
            " Loss: 0.184911\n",
            "Epoch : 40 [2560/5768 (44%)]\n",
            " Loss: 0.235242\n",
            "Epoch : 50 [3200/5768 (55%)]\n",
            " Loss: 0.020939\n",
            "Epoch : 60 [3840/5768 (66%)]\n",
            " Loss: 0.057507\n",
            "Epoch : 70 [4480/5768 (77%)]\n",
            " Loss: 0.104509\n",
            "Epoch : 80 [5120/5768 (88%)]\n",
            " Loss: 0.020931\n",
            "Epoch : 90 [720/5768 (99%)]\n",
            " Loss: 0.000398\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1987, Accuracy: 9597/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 232\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5832 (0%)]\n",
            " Loss: 0.024386\n",
            "Epoch : 10 [640/5832 (11%)]\n",
            " Loss: 0.011849\n",
            "Epoch : 20 [1280/5832 (22%)]\n",
            " Loss: 0.014922\n",
            "Epoch : 30 [1920/5832 (33%)]\n",
            " Loss: 0.005630\n",
            "Epoch : 40 [2560/5832 (43%)]\n",
            " Loss: 0.004287\n",
            "Epoch : 50 [3200/5832 (54%)]\n",
            " Loss: 0.013913\n",
            "Epoch : 60 [3840/5832 (65%)]\n",
            " Loss: 0.182405\n",
            "Epoch : 70 [4480/5832 (76%)]\n",
            " Loss: 0.016791\n",
            "Epoch : 80 [5120/5832 (87%)]\n",
            " Loss: 0.017014\n",
            "Epoch : 90 [5760/5832 (98%)]\n",
            " Loss: 0.019770\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1858, Accuracy: 9608/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 168\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5896 (0%)]\n",
            " Loss: 0.017858\n",
            "Epoch : 10 [640/5896 (11%)]\n",
            " Loss: 0.026825\n",
            "Epoch : 20 [1280/5896 (22%)]\n",
            " Loss: 0.010755\n",
            "Epoch : 30 [1920/5896 (32%)]\n",
            " Loss: 0.001921\n",
            "Epoch : 40 [2560/5896 (43%)]\n",
            " Loss: 0.058380\n",
            "Epoch : 50 [3200/5896 (54%)]\n",
            " Loss: 0.011955\n",
            "Epoch : 60 [3840/5896 (65%)]\n",
            " Loss: 0.012709\n",
            "Epoch : 70 [4480/5896 (75%)]\n",
            " Loss: 0.026829\n",
            "Epoch : 80 [5120/5896 (86%)]\n",
            " Loss: 0.027024\n",
            "Epoch : 90 [5760/5896 (97%)]\n",
            " Loss: 0.067311\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.1943, Accuracy: 9602/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 104\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5960 (0%)]\n",
            " Loss: 0.017850\n",
            "Epoch : 10 [640/5960 (11%)]\n",
            " Loss: 0.024144\n",
            "Epoch : 20 [1280/5960 (21%)]\n",
            " Loss: 0.064574\n",
            "Epoch : 30 [1920/5960 (32%)]\n",
            " Loss: 0.098441\n",
            "Epoch : 40 [2560/5960 (43%)]\n",
            " Loss: 0.090805\n",
            "Epoch : 50 [3200/5960 (53%)]\n",
            " Loss: 0.036907\n",
            "Epoch : 60 [3840/5960 (64%)]\n",
            " Loss: 0.007017\n",
            "Epoch : 70 [4480/5960 (74%)]\n",
            " Loss: 0.009465\n",
            "Epoch : 80 [5120/5960 (85%)]\n",
            " Loss: 0.007381\n",
            "Epoch : 90 [5760/5960 (96%)]\n",
            " Loss: 0.002223\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2000, Accuracy: 9613/10000 (96%)\n",
            "\n",
            "Using MaxEntropy Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 40\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/6000 (0%)]\n",
            " Loss: 0.014301\n",
            "Epoch : 10 [640/6000 (11%)]\n",
            " Loss: 0.019765\n",
            "Epoch : 20 [1280/6000 (21%)]\n",
            " Loss: 0.039777\n",
            "Epoch : 30 [1920/6000 (32%)]\n",
            " Loss: 0.002038\n",
            "Epoch : 40 [2560/6000 (43%)]\n",
            " Loss: 0.008104\n",
            "Epoch : 50 [3200/6000 (53%)]\n",
            " Loss: 0.028106\n",
            "Epoch : 60 [3840/6000 (64%)]\n",
            " Loss: 0.021520\n",
            "Epoch : 70 [4480/6000 (74%)]\n",
            " Loss: 0.066645\n",
            "Epoch : 80 [5120/6000 (85%)]\n",
            " Loss: 0.073541\n",
            "Epoch : 90 [5760/6000 (96%)]\n",
            " Loss: 0.122326\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2215, Accuracy: 9568/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 1000\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5064 (0%)]\n",
            " Loss: 0.138080\n",
            "Epoch : 10 [640/5064 (12%)]\n",
            " Loss: 0.134937\n",
            "Epoch : 20 [1280/5064 (25%)]\n",
            " Loss: 0.019922\n",
            "Epoch : 30 [1920/5064 (38%)]\n",
            " Loss: 0.025128\n",
            "Epoch : 40 [2560/5064 (50%)]\n",
            " Loss: 0.009062\n",
            "Epoch : 50 [3200/5064 (62%)]\n",
            " Loss: 0.026813\n",
            "Epoch : 60 [3840/5064 (75%)]\n",
            " Loss: 0.010147\n",
            "Epoch : 70 [4480/5064 (88%)]\n",
            " Loss: 0.007793\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2881, Accuracy: 9608/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 936\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5128 (0%)]\n",
            " Loss: 0.000283\n",
            "Epoch : 10 [640/5128 (12%)]\n",
            " Loss: 0.106401\n",
            "Epoch : 20 [1280/5128 (25%)]\n",
            " Loss: 0.000108\n",
            "Epoch : 30 [1920/5128 (37%)]\n",
            " Loss: 0.021333\n",
            "Epoch : 40 [2560/5128 (49%)]\n",
            " Loss: 0.094836\n",
            "Epoch : 50 [3200/5128 (62%)]\n",
            " Loss: 0.096193\n",
            "Epoch : 60 [3840/5128 (74%)]\n",
            " Loss: 0.001089\n",
            "Epoch : 70 [4480/5128 (86%)]\n",
            " Loss: 0.065656\n",
            "Epoch : 80 [640/5128 (99%)]\n",
            " Loss: 0.000031\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2870, Accuracy: 9605/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 872\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5192 (0%)]\n",
            " Loss: 0.125463\n",
            "Epoch : 10 [640/5192 (12%)]\n",
            " Loss: 0.025578\n",
            "Epoch : 20 [1280/5192 (24%)]\n",
            " Loss: 0.017446\n",
            "Epoch : 30 [1920/5192 (37%)]\n",
            " Loss: 0.042907\n",
            "Epoch : 40 [2560/5192 (49%)]\n",
            " Loss: 0.000754\n",
            "Epoch : 50 [3200/5192 (61%)]\n",
            " Loss: 0.003251\n",
            "Epoch : 60 [3840/5192 (73%)]\n",
            " Loss: 0.092925\n",
            "Epoch : 70 [4480/5192 (85%)]\n",
            " Loss: 0.038905\n",
            "Epoch : 80 [5120/5192 (98%)]\n",
            " Loss: 0.080203\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3127, Accuracy: 9574/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 808\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5256 (0%)]\n",
            " Loss: 0.006092\n",
            "Epoch : 10 [640/5256 (12%)]\n",
            " Loss: 0.052605\n",
            "Epoch : 20 [1280/5256 (24%)]\n",
            " Loss: 0.023878\n",
            "Epoch : 30 [1920/5256 (36%)]\n",
            " Loss: 0.033501\n",
            "Epoch : 40 [2560/5256 (48%)]\n",
            " Loss: 0.018569\n",
            "Epoch : 50 [3200/5256 (60%)]\n",
            " Loss: 0.107928\n",
            "Epoch : 60 [3840/5256 (72%)]\n",
            " Loss: 0.071247\n",
            "Epoch : 70 [4480/5256 (84%)]\n",
            " Loss: 0.142132\n",
            "Epoch : 80 [5120/5256 (96%)]\n",
            " Loss: 0.061950\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3025, Accuracy: 9566/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 744\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5320 (0%)]\n",
            " Loss: 0.127075\n",
            "Epoch : 10 [640/5320 (12%)]\n",
            " Loss: 0.139388\n",
            "Epoch : 20 [1280/5320 (24%)]\n",
            " Loss: 0.009503\n",
            "Epoch : 30 [1920/5320 (36%)]\n",
            " Loss: 0.050744\n",
            "Epoch : 40 [2560/5320 (48%)]\n",
            " Loss: 0.023542\n",
            "Epoch : 50 [3200/5320 (60%)]\n",
            " Loss: 0.136133\n",
            "Epoch : 60 [3840/5320 (71%)]\n",
            " Loss: 0.020179\n",
            "Epoch : 70 [4480/5320 (83%)]\n",
            " Loss: 0.001846\n",
            "Epoch : 80 [5120/5320 (95%)]\n",
            " Loss: 0.084708\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2803, Accuracy: 9592/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 680\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5384 (0%)]\n",
            " Loss: 0.003571\n",
            "Epoch : 10 [640/5384 (12%)]\n",
            " Loss: 0.013814\n",
            "Epoch : 20 [1280/5384 (24%)]\n",
            " Loss: 0.057073\n",
            "Epoch : 30 [1920/5384 (35%)]\n",
            " Loss: 0.047596\n",
            "Epoch : 40 [2560/5384 (47%)]\n",
            " Loss: 0.033849\n",
            "Epoch : 50 [3200/5384 (59%)]\n",
            " Loss: 0.095822\n",
            "Epoch : 60 [3840/5384 (71%)]\n",
            " Loss: 0.044821\n",
            "Epoch : 70 [4480/5384 (82%)]\n",
            " Loss: 0.000608\n",
            "Epoch : 80 [5120/5384 (94%)]\n",
            " Loss: 0.116801\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2642, Accuracy: 9610/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 616\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5448 (0%)]\n",
            " Loss: 0.001998\n",
            "Epoch : 10 [640/5448 (12%)]\n",
            " Loss: 0.022573\n",
            "Epoch : 20 [1280/5448 (23%)]\n",
            " Loss: 0.069650\n",
            "Epoch : 30 [1920/5448 (35%)]\n",
            " Loss: 0.037331\n",
            "Epoch : 40 [2560/5448 (47%)]\n",
            " Loss: 0.001975\n",
            "Epoch : 50 [3200/5448 (58%)]\n",
            " Loss: 0.045212\n",
            "Epoch : 60 [3840/5448 (70%)]\n",
            " Loss: 0.010983\n",
            "Epoch : 70 [4480/5448 (81%)]\n",
            " Loss: 0.062012\n",
            "Epoch : 80 [5120/5448 (93%)]\n",
            " Loss: 0.062315\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2960, Accuracy: 9605/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 552\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5512 (0%)]\n",
            " Loss: 0.000037\n",
            "Epoch : 10 [640/5512 (11%)]\n",
            " Loss: 0.036277\n",
            "Epoch : 20 [1280/5512 (23%)]\n",
            " Loss: 0.006983\n",
            "Epoch : 30 [1920/5512 (34%)]\n",
            " Loss: 0.041516\n",
            "Epoch : 40 [2560/5512 (46%)]\n",
            " Loss: 0.121372\n",
            "Epoch : 50 [3200/5512 (57%)]\n",
            " Loss: 0.035258\n",
            "Epoch : 60 [3840/5512 (69%)]\n",
            " Loss: 0.006940\n",
            "Epoch : 70 [4480/5512 (80%)]\n",
            " Loss: 0.001070\n",
            "Epoch : 80 [5120/5512 (92%)]\n",
            " Loss: 0.087852\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2372, Accuracy: 9649/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 488\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5576 (0%)]\n",
            " Loss: 0.004120\n",
            "Epoch : 10 [640/5576 (11%)]\n",
            " Loss: 0.000784\n",
            "Epoch : 20 [1280/5576 (23%)]\n",
            " Loss: 0.001836\n",
            "Epoch : 30 [1920/5576 (34%)]\n",
            " Loss: 0.019828\n",
            "Epoch : 40 [2560/5576 (45%)]\n",
            " Loss: 0.030828\n",
            "Epoch : 50 [3200/5576 (57%)]\n",
            " Loss: 0.004652\n",
            "Epoch : 60 [3840/5576 (68%)]\n",
            " Loss: 0.023160\n",
            "Epoch : 70 [4480/5576 (80%)]\n",
            " Loss: 0.023283\n",
            "Epoch : 80 [5120/5576 (91%)]\n",
            " Loss: 0.010575\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2874, Accuracy: 9605/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 424\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5640 (0%)]\n",
            " Loss: 0.001201\n",
            "Epoch : 10 [640/5640 (11%)]\n",
            " Loss: 0.000105\n",
            "Epoch : 20 [1280/5640 (22%)]\n",
            " Loss: 0.000418\n",
            "Epoch : 30 [1920/5640 (34%)]\n",
            " Loss: 0.000160\n",
            "Epoch : 40 [2560/5640 (45%)]\n",
            " Loss: 0.188959\n",
            "Epoch : 50 [3200/5640 (56%)]\n",
            " Loss: 0.061806\n",
            "Epoch : 60 [3840/5640 (67%)]\n",
            " Loss: 0.049285\n",
            "Epoch : 70 [4480/5640 (79%)]\n",
            " Loss: 0.011239\n",
            "Epoch : 80 [5120/5640 (90%)]\n",
            " Loss: 0.087703\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2976, Accuracy: 9537/10000 (95%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 360\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5704 (0%)]\n",
            " Loss: 0.262527\n",
            "Epoch : 10 [640/5704 (11%)]\n",
            " Loss: 0.008016\n",
            "Epoch : 20 [1280/5704 (22%)]\n",
            " Loss: 0.015973\n",
            "Epoch : 30 [1920/5704 (33%)]\n",
            " Loss: 0.015732\n",
            "Epoch : 40 [2560/5704 (44%)]\n",
            " Loss: 0.053918\n",
            "Epoch : 50 [3200/5704 (56%)]\n",
            " Loss: 0.037712\n",
            "Epoch : 60 [3840/5704 (67%)]\n",
            " Loss: 0.008295\n",
            "Epoch : 70 [4480/5704 (78%)]\n",
            " Loss: 0.047085\n",
            "Epoch : 80 [5120/5704 (89%)]\n",
            " Loss: 0.026228\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2838, Accuracy: 9585/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 296\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5768 (0%)]\n",
            " Loss: 0.014006\n",
            "Epoch : 10 [640/5768 (11%)]\n",
            " Loss: 0.005486\n",
            "Epoch : 20 [1280/5768 (22%)]\n",
            " Loss: 0.038468\n",
            "Epoch : 30 [1920/5768 (33%)]\n",
            " Loss: 0.111767\n",
            "Epoch : 40 [2560/5768 (44%)]\n",
            " Loss: 0.072981\n",
            "Epoch : 50 [3200/5768 (55%)]\n",
            " Loss: 0.011841\n",
            "Epoch : 60 [3840/5768 (66%)]\n",
            " Loss: 0.038635\n",
            "Epoch : 70 [4480/5768 (77%)]\n",
            " Loss: 0.006154\n",
            "Epoch : 80 [5120/5768 (88%)]\n",
            " Loss: 0.003645\n",
            "Epoch : 90 [720/5768 (99%)]\n",
            " Loss: 0.003171\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2444, Accuracy: 9611/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 232\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5832 (0%)]\n",
            " Loss: 0.001285\n",
            "Epoch : 10 [640/5832 (11%)]\n",
            " Loss: 0.094067\n",
            "Epoch : 20 [1280/5832 (22%)]\n",
            " Loss: 0.047927\n",
            "Epoch : 30 [1920/5832 (33%)]\n",
            " Loss: 0.003361\n",
            "Epoch : 40 [2560/5832 (43%)]\n",
            " Loss: 0.134142\n",
            "Epoch : 50 [3200/5832 (54%)]\n",
            " Loss: 0.000859\n",
            "Epoch : 60 [3840/5832 (65%)]\n",
            " Loss: 0.074852\n",
            "Epoch : 70 [4480/5832 (76%)]\n",
            " Loss: 0.041114\n",
            "Epoch : 80 [5120/5832 (87%)]\n",
            " Loss: 0.009501\n",
            "Epoch : 90 [5760/5832 (98%)]\n",
            " Loss: 0.000337\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2612, Accuracy: 9578/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 168\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5896 (0%)]\n",
            " Loss: 0.000375\n",
            "Epoch : 10 [640/5896 (11%)]\n",
            " Loss: 0.015542\n",
            "Epoch : 20 [1280/5896 (22%)]\n",
            " Loss: 0.004103\n",
            "Epoch : 30 [1920/5896 (32%)]\n",
            " Loss: 0.050617\n",
            "Epoch : 40 [2560/5896 (43%)]\n",
            " Loss: 0.026294\n",
            "Epoch : 50 [3200/5896 (54%)]\n",
            " Loss: 0.011318\n",
            "Epoch : 60 [3840/5896 (65%)]\n",
            " Loss: 0.010465\n",
            "Epoch : 70 [4480/5896 (75%)]\n",
            " Loss: 0.001714\n",
            "Epoch : 80 [5120/5896 (86%)]\n",
            " Loss: 0.004628\n",
            "Epoch : 90 [5760/5896 (97%)]\n",
            " Loss: 0.028832\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2479, Accuracy: 9645/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 104\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5960 (0%)]\n",
            " Loss: 0.009275\n",
            "Epoch : 10 [640/5960 (11%)]\n",
            " Loss: 0.175078\n",
            "Epoch : 20 [1280/5960 (21%)]\n",
            " Loss: 0.044991\n",
            "Epoch : 30 [1920/5960 (32%)]\n",
            " Loss: 0.007134\n",
            "Epoch : 40 [2560/5960 (43%)]\n",
            " Loss: 0.003224\n",
            "Epoch : 50 [3200/5960 (53%)]\n",
            " Loss: 0.010246\n",
            "Epoch : 60 [3840/5960 (64%)]\n",
            " Loss: 0.024866\n",
            "Epoch : 70 [4480/5960 (74%)]\n",
            " Loss: 0.048144\n",
            "Epoch : 80 [5120/5960 (85%)]\n",
            " Loss: 0.065574\n",
            "Epoch : 90 [5760/5960 (96%)]\n",
            " Loss: 0.094701\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2618, Accuracy: 9597/10000 (96%)\n",
            "\n",
            "Using VariationRatios Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 40\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/6000 (0%)]\n",
            " Loss: 0.001509\n",
            "Epoch : 10 [640/6000 (11%)]\n",
            " Loss: 0.000395\n",
            "Epoch : 20 [1280/6000 (21%)]\n",
            " Loss: 0.253668\n",
            "Epoch : 30 [1920/6000 (32%)]\n",
            " Loss: 0.006649\n",
            "Epoch : 40 [2560/6000 (43%)]\n",
            " Loss: 0.132980\n",
            "Epoch : 50 [3200/6000 (53%)]\n",
            " Loss: 0.009781\n",
            "Epoch : 60 [3840/6000 (64%)]\n",
            " Loss: 0.002779\n",
            "Epoch : 70 [4480/6000 (74%)]\n",
            " Loss: 0.051267\n",
            "Epoch : 80 [5120/6000 (85%)]\n",
            " Loss: 0.017146\n",
            "Epoch : 90 [5760/6000 (96%)]\n",
            " Loss: 0.011333\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2401, Accuracy: 9620/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 1000\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5064 (0%)]\n",
            " Loss: 0.012901\n",
            "Epoch : 10 [640/5064 (12%)]\n",
            " Loss: 0.007019\n",
            "Epoch : 20 [1280/5064 (25%)]\n",
            " Loss: 0.008183\n",
            "Epoch : 30 [1920/5064 (38%)]\n",
            " Loss: 0.000099\n",
            "Epoch : 40 [2560/5064 (50%)]\n",
            " Loss: 0.002830\n",
            "Epoch : 50 [3200/5064 (62%)]\n",
            " Loss: 0.003189\n",
            "Epoch : 60 [3840/5064 (75%)]\n",
            " Loss: 0.000024\n",
            "Epoch : 70 [4480/5064 (88%)]\n",
            " Loss: 0.081693\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3404, Accuracy: 9640/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 936\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5128 (0%)]\n",
            " Loss: 0.004216\n",
            "Epoch : 10 [640/5128 (12%)]\n",
            " Loss: 0.010717\n",
            "Epoch : 20 [1280/5128 (25%)]\n",
            " Loss: 0.000435\n",
            "Epoch : 30 [1920/5128 (37%)]\n",
            " Loss: 0.119190\n",
            "Epoch : 40 [2560/5128 (49%)]\n",
            " Loss: 0.001302\n",
            "Epoch : 50 [3200/5128 (62%)]\n",
            " Loss: 0.000016\n",
            "Epoch : 60 [3840/5128 (74%)]\n",
            " Loss: 0.020094\n",
            "Epoch : 70 [4480/5128 (86%)]\n",
            " Loss: 0.003708\n",
            "Epoch : 80 [640/5128 (99%)]\n",
            " Loss: 0.000001\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3644, Accuracy: 9610/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 872\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5192 (0%)]\n",
            " Loss: 0.092809\n",
            "Epoch : 10 [640/5192 (12%)]\n",
            " Loss: 0.011094\n",
            "Epoch : 20 [1280/5192 (24%)]\n",
            " Loss: 0.000199\n",
            "Epoch : 30 [1920/5192 (37%)]\n",
            " Loss: 0.001493\n",
            "Epoch : 40 [2560/5192 (49%)]\n",
            " Loss: 0.000128\n",
            "Epoch : 50 [3200/5192 (61%)]\n",
            " Loss: 0.001056\n",
            "Epoch : 60 [3840/5192 (73%)]\n",
            " Loss: 0.072941\n",
            "Epoch : 70 [4480/5192 (85%)]\n",
            " Loss: 0.007345\n",
            "Epoch : 80 [5120/5192 (98%)]\n",
            " Loss: 0.137755\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3581, Accuracy: 9587/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 808\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5256 (0%)]\n",
            " Loss: 0.012620\n",
            "Epoch : 10 [640/5256 (12%)]\n",
            " Loss: 0.000315\n",
            "Epoch : 20 [1280/5256 (24%)]\n",
            " Loss: 0.066834\n",
            "Epoch : 30 [1920/5256 (36%)]\n",
            " Loss: 0.001962\n",
            "Epoch : 40 [2560/5256 (48%)]\n",
            " Loss: 0.001990\n",
            "Epoch : 50 [3200/5256 (60%)]\n",
            " Loss: 0.081707\n",
            "Epoch : 60 [3840/5256 (72%)]\n",
            " Loss: 0.000284\n",
            "Epoch : 70 [4480/5256 (84%)]\n",
            " Loss: 0.062431\n",
            "Epoch : 80 [5120/5256 (96%)]\n",
            " Loss: 0.103828\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3715, Accuracy: 9606/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 744\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5320 (0%)]\n",
            " Loss: 0.010508\n",
            "Epoch : 10 [640/5320 (12%)]\n",
            " Loss: 0.002475\n",
            "Epoch : 20 [1280/5320 (24%)]\n",
            " Loss: 0.051577\n",
            "Epoch : 30 [1920/5320 (36%)]\n",
            " Loss: 0.002493\n",
            "Epoch : 40 [2560/5320 (48%)]\n",
            " Loss: 0.028760\n",
            "Epoch : 50 [3200/5320 (60%)]\n",
            " Loss: 0.002013\n",
            "Epoch : 60 [3840/5320 (71%)]\n",
            " Loss: 0.000946\n",
            "Epoch : 70 [4480/5320 (83%)]\n",
            " Loss: 0.035995\n",
            "Epoch : 80 [5120/5320 (95%)]\n",
            " Loss: 0.000117\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3931, Accuracy: 9553/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 680\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5384 (0%)]\n",
            " Loss: 0.007944\n",
            "Epoch : 10 [640/5384 (12%)]\n",
            " Loss: 0.002378\n",
            "Epoch : 20 [1280/5384 (24%)]\n",
            " Loss: 0.000474\n",
            "Epoch : 30 [1920/5384 (35%)]\n",
            " Loss: 0.129349\n",
            "Epoch : 40 [2560/5384 (47%)]\n",
            " Loss: 0.000008\n",
            "Epoch : 50 [3200/5384 (59%)]\n",
            " Loss: 0.001046\n",
            "Epoch : 60 [3840/5384 (71%)]\n",
            " Loss: 0.077624\n",
            "Epoch : 70 [4480/5384 (82%)]\n",
            " Loss: 0.000374\n",
            "Epoch : 80 [5120/5384 (94%)]\n",
            " Loss: 0.002617\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3306, Accuracy: 9611/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 616\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5448 (0%)]\n",
            " Loss: 0.061192\n",
            "Epoch : 10 [640/5448 (12%)]\n",
            " Loss: 0.223141\n",
            "Epoch : 20 [1280/5448 (23%)]\n",
            " Loss: 0.002026\n",
            "Epoch : 30 [1920/5448 (35%)]\n",
            " Loss: 0.004333\n",
            "Epoch : 40 [2560/5448 (47%)]\n",
            " Loss: 0.031563\n",
            "Epoch : 50 [3200/5448 (58%)]\n",
            " Loss: 0.009230\n",
            "Epoch : 60 [3840/5448 (70%)]\n",
            " Loss: 0.026929\n",
            "Epoch : 70 [4480/5448 (81%)]\n",
            " Loss: 0.000485\n",
            "Epoch : 80 [5120/5448 (93%)]\n",
            " Loss: 0.041142\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2987, Accuracy: 9601/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 552\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5512 (0%)]\n",
            " Loss: 0.015153\n",
            "Epoch : 10 [640/5512 (11%)]\n",
            " Loss: 0.004483\n",
            "Epoch : 20 [1280/5512 (23%)]\n",
            " Loss: 0.000028\n",
            "Epoch : 30 [1920/5512 (34%)]\n",
            " Loss: 0.007039\n",
            "Epoch : 40 [2560/5512 (46%)]\n",
            " Loss: 0.001823\n",
            "Epoch : 50 [3200/5512 (57%)]\n",
            " Loss: 0.022920\n",
            "Epoch : 60 [3840/5512 (69%)]\n",
            " Loss: 0.045561\n",
            "Epoch : 70 [4480/5512 (80%)]\n",
            " Loss: 0.119757\n",
            "Epoch : 80 [5120/5512 (92%)]\n",
            " Loss: 0.108466\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3025, Accuracy: 9651/10000 (97%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 488\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5576 (0%)]\n",
            " Loss: 0.015516\n",
            "Epoch : 10 [640/5576 (11%)]\n",
            " Loss: 0.084790\n",
            "Epoch : 20 [1280/5576 (23%)]\n",
            " Loss: 0.026320\n",
            "Epoch : 30 [1920/5576 (34%)]\n",
            " Loss: 0.010078\n",
            "Epoch : 40 [2560/5576 (45%)]\n",
            " Loss: 0.001464\n",
            "Epoch : 50 [3200/5576 (57%)]\n",
            " Loss: 0.013518\n",
            "Epoch : 60 [3840/5576 (68%)]\n",
            " Loss: 0.066632\n",
            "Epoch : 70 [4480/5576 (80%)]\n",
            " Loss: 0.069740\n",
            "Epoch : 80 [5120/5576 (91%)]\n",
            " Loss: 0.013149\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3467, Accuracy: 9591/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 424\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5640 (0%)]\n",
            " Loss: 0.011390\n",
            "Epoch : 10 [640/5640 (11%)]\n",
            " Loss: 0.036970\n",
            "Epoch : 20 [1280/5640 (22%)]\n",
            " Loss: 0.098701\n",
            "Epoch : 30 [1920/5640 (34%)]\n",
            " Loss: 0.051717\n",
            "Epoch : 40 [2560/5640 (45%)]\n",
            " Loss: 0.043640\n",
            "Epoch : 50 [3200/5640 (56%)]\n",
            " Loss: 0.234314\n",
            "Epoch : 60 [3840/5640 (67%)]\n",
            " Loss: 0.000495\n",
            "Epoch : 70 [4480/5640 (79%)]\n",
            " Loss: 0.117900\n",
            "Epoch : 80 [5120/5640 (90%)]\n",
            " Loss: 0.017809\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3561, Accuracy: 9630/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 360\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5704 (0%)]\n",
            " Loss: 0.065660\n",
            "Epoch : 10 [640/5704 (11%)]\n",
            " Loss: 0.005585\n",
            "Epoch : 20 [1280/5704 (22%)]\n",
            " Loss: 0.003945\n",
            "Epoch : 30 [1920/5704 (33%)]\n",
            " Loss: 0.000758\n",
            "Epoch : 40 [2560/5704 (44%)]\n",
            " Loss: 0.017080\n",
            "Epoch : 50 [3200/5704 (56%)]\n",
            " Loss: 0.002129\n",
            "Epoch : 60 [3840/5704 (67%)]\n",
            " Loss: 0.000451\n",
            "Epoch : 70 [4480/5704 (78%)]\n",
            " Loss: 0.004637\n",
            "Epoch : 80 [5120/5704 (89%)]\n",
            " Loss: 0.123820\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3521, Accuracy: 9590/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 296\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5768 (0%)]\n",
            " Loss: 0.236637\n",
            "Epoch : 10 [640/5768 (11%)]\n",
            " Loss: 0.017424\n",
            "Epoch : 20 [1280/5768 (22%)]\n",
            " Loss: 0.091320\n",
            "Epoch : 30 [1920/5768 (33%)]\n",
            " Loss: 0.186646\n",
            "Epoch : 40 [2560/5768 (44%)]\n",
            " Loss: 0.029080\n",
            "Epoch : 50 [3200/5768 (55%)]\n",
            " Loss: 0.152294\n",
            "Epoch : 60 [3840/5768 (66%)]\n",
            " Loss: 0.017190\n",
            "Epoch : 70 [4480/5768 (77%)]\n",
            " Loss: 0.009131\n",
            "Epoch : 80 [5120/5768 (88%)]\n",
            " Loss: 0.001318\n",
            "Epoch : 90 [720/5768 (99%)]\n",
            " Loss: 0.289815\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2937, Accuracy: 9608/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 232\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5832 (0%)]\n",
            " Loss: 0.017787\n",
            "Epoch : 10 [640/5832 (11%)]\n",
            " Loss: 0.029632\n",
            "Epoch : 20 [1280/5832 (22%)]\n",
            " Loss: 0.209855\n",
            "Epoch : 30 [1920/5832 (33%)]\n",
            " Loss: 0.086143\n",
            "Epoch : 40 [2560/5832 (43%)]\n",
            " Loss: 0.072949\n",
            "Epoch : 50 [3200/5832 (54%)]\n",
            " Loss: 0.072043\n",
            "Epoch : 60 [3840/5832 (65%)]\n",
            " Loss: 0.000432\n",
            "Epoch : 70 [4480/5832 (76%)]\n",
            " Loss: 0.057582\n",
            "Epoch : 80 [5120/5832 (87%)]\n",
            " Loss: 0.008165\n",
            "Epoch : 90 [5760/5832 (98%)]\n",
            " Loss: 0.001652\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2987, Accuracy: 9600/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 168\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5896 (0%)]\n",
            " Loss: 0.251255\n",
            "Epoch : 10 [640/5896 (11%)]\n",
            " Loss: 0.066301\n",
            "Epoch : 20 [1280/5896 (22%)]\n",
            " Loss: 0.022299\n",
            "Epoch : 30 [1920/5896 (32%)]\n",
            " Loss: 0.057740\n",
            "Epoch : 40 [2560/5896 (43%)]\n",
            " Loss: 0.009908\n",
            "Epoch : 50 [3200/5896 (54%)]\n",
            " Loss: 0.029357\n",
            "Epoch : 60 [3840/5896 (65%)]\n",
            " Loss: 0.040824\n",
            "Epoch : 70 [4480/5896 (75%)]\n",
            " Loss: 0.145978\n",
            "Epoch : 80 [5120/5896 (86%)]\n",
            " Loss: 0.093132\n",
            "Epoch : 90 [5760/5896 (97%)]\n",
            " Loss: 0.014624\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2933, Accuracy: 9583/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 104\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5960 (0%)]\n",
            " Loss: 0.076918\n",
            "Epoch : 10 [640/5960 (11%)]\n",
            " Loss: 0.021068\n",
            "Epoch : 20 [1280/5960 (21%)]\n",
            " Loss: 0.001318\n",
            "Epoch : 30 [1920/5960 (32%)]\n",
            " Loss: 0.025638\n",
            "Epoch : 40 [2560/5960 (43%)]\n",
            " Loss: 0.001397\n",
            "Epoch : 50 [3200/5960 (53%)]\n",
            " Loss: 0.002326\n",
            "Epoch : 60 [3840/5960 (64%)]\n",
            " Loss: 0.012086\n",
            "Epoch : 70 [4480/5960 (74%)]\n",
            " Loss: 0.139016\n",
            "Epoch : 80 [5120/5960 (85%)]\n",
            " Loss: 0.058273\n",
            "Epoch : 90 [5760/5960 (96%)]\n",
            " Loss: 0.001156\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.2746, Accuracy: 9625/10000 (96%)\n",
            "\n",
            "Using BALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 40\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/6000 (0%)]\n",
            " Loss: 0.161617\n",
            "Epoch : 10 [640/6000 (11%)]\n",
            " Loss: 0.018014\n",
            "Epoch : 20 [1280/6000 (21%)]\n",
            " Loss: 0.254528\n",
            "Epoch : 30 [1920/6000 (32%)]\n",
            " Loss: 0.112936\n",
            "Epoch : 40 [2560/6000 (43%)]\n",
            " Loss: 0.000385\n",
            "Epoch : 50 [3200/6000 (53%)]\n",
            " Loss: 0.000754\n",
            "Epoch : 60 [3840/6000 (64%)]\n",
            " Loss: 0.019839\n",
            "Epoch : 70 [4480/6000 (74%)]\n",
            " Loss: 0.024994\n",
            "Epoch : 80 [5120/6000 (85%)]\n",
            " Loss: 0.000215\n",
            "Epoch : 90 [5760/6000 (96%)]\n",
            " Loss: 0.100334\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3201, Accuracy: 9584/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 1000\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5064 (0%)]\n",
            " Loss: 0.109761\n",
            "Epoch : 10 [640/5064 (12%)]\n",
            " Loss: 0.030522\n",
            "Epoch : 20 [1280/5064 (25%)]\n",
            " Loss: 0.000022\n",
            "Epoch : 30 [1920/5064 (38%)]\n",
            " Loss: 0.024459\n",
            "Epoch : 40 [2560/5064 (50%)]\n",
            " Loss: 0.153682\n",
            "Epoch : 50 [3200/5064 (62%)]\n",
            " Loss: 0.038159\n",
            "Epoch : 60 [3840/5064 (75%)]\n",
            " Loss: 0.004470\n",
            "Epoch : 70 [4480/5064 (88%)]\n",
            " Loss: 0.001558\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3906, Accuracy: 9627/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 936\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5128 (0%)]\n",
            " Loss: 0.011583\n",
            "Epoch : 10 [640/5128 (12%)]\n",
            " Loss: 0.000021\n",
            "Epoch : 20 [1280/5128 (25%)]\n",
            " Loss: 0.001601\n",
            "Epoch : 30 [1920/5128 (37%)]\n",
            " Loss: 0.032545\n",
            "Epoch : 40 [2560/5128 (49%)]\n",
            " Loss: 0.001835\n",
            "Epoch : 50 [3200/5128 (62%)]\n",
            " Loss: 0.110409\n",
            "Epoch : 60 [3840/5128 (74%)]\n",
            " Loss: 0.015477\n",
            "Epoch : 70 [4480/5128 (86%)]\n",
            " Loss: 0.001279\n",
            "Epoch : 80 [640/5128 (99%)]\n",
            " Loss: 0.000000\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.4375, Accuracy: 9602/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 872\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5192 (0%)]\n",
            " Loss: 0.000109\n",
            "Epoch : 10 [640/5192 (12%)]\n",
            " Loss: 0.000015\n",
            "Epoch : 20 [1280/5192 (24%)]\n",
            " Loss: 0.047105\n",
            "Epoch : 30 [1920/5192 (37%)]\n",
            " Loss: 0.002881\n",
            "Epoch : 40 [2560/5192 (49%)]\n",
            " Loss: 0.001455\n",
            "Epoch : 50 [3200/5192 (61%)]\n",
            " Loss: 0.000324\n",
            "Epoch : 60 [3840/5192 (73%)]\n",
            " Loss: 0.142701\n",
            "Epoch : 70 [4480/5192 (85%)]\n",
            " Loss: 0.234260\n",
            "Epoch : 80 [5120/5192 (98%)]\n",
            " Loss: 0.031593\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.4447, Accuracy: 9579/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 808\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5256 (0%)]\n",
            " Loss: 0.166370\n",
            "Epoch : 10 [640/5256 (12%)]\n",
            " Loss: 0.000008\n",
            "Epoch : 20 [1280/5256 (24%)]\n",
            " Loss: 0.096001\n",
            "Epoch : 30 [1920/5256 (36%)]\n",
            " Loss: 0.484675\n",
            "Epoch : 40 [2560/5256 (48%)]\n",
            " Loss: 0.000377\n",
            "Epoch : 50 [3200/5256 (60%)]\n",
            " Loss: 0.000557\n",
            "Epoch : 60 [3840/5256 (72%)]\n",
            " Loss: 0.170009\n",
            "Epoch : 70 [4480/5256 (84%)]\n",
            " Loss: 0.015529\n",
            "Epoch : 80 [5120/5256 (96%)]\n",
            " Loss: 0.283228\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.4273, Accuracy: 9612/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 744\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5320 (0%)]\n",
            " Loss: 0.000581\n",
            "Epoch : 10 [640/5320 (12%)]\n",
            " Loss: 0.000108\n",
            "Epoch : 20 [1280/5320 (24%)]\n",
            " Loss: 0.003087\n",
            "Epoch : 30 [1920/5320 (36%)]\n",
            " Loss: 0.035355\n",
            "Epoch : 40 [2560/5320 (48%)]\n",
            " Loss: 0.013939\n",
            "Epoch : 50 [3200/5320 (60%)]\n",
            " Loss: 0.203013\n",
            "Epoch : 60 [3840/5320 (71%)]\n",
            " Loss: 0.028752\n",
            "Epoch : 70 [4480/5320 (83%)]\n",
            " Loss: 0.000299\n",
            "Epoch : 80 [5120/5320 (95%)]\n",
            " Loss: 0.000172\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.5863, Accuracy: 9496/10000 (95%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 680\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5384 (0%)]\n",
            " Loss: 0.008991\n",
            "Epoch : 10 [640/5384 (12%)]\n",
            " Loss: 0.087417\n",
            "Epoch : 20 [1280/5384 (24%)]\n",
            " Loss: 0.060726\n",
            "Epoch : 30 [1920/5384 (35%)]\n",
            " Loss: 0.055247\n",
            "Epoch : 40 [2560/5384 (47%)]\n",
            " Loss: 0.000383\n",
            "Epoch : 50 [3200/5384 (59%)]\n",
            " Loss: 0.166109\n",
            "Epoch : 60 [3840/5384 (71%)]\n",
            " Loss: 0.067292\n",
            "Epoch : 70 [4480/5384 (82%)]\n",
            " Loss: 0.055066\n",
            "Epoch : 80 [5120/5384 (94%)]\n",
            " Loss: 0.005769\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3591, Accuracy: 9592/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 616\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5448 (0%)]\n",
            " Loss: 0.001444\n",
            "Epoch : 10 [640/5448 (12%)]\n",
            " Loss: 0.055801\n",
            "Epoch : 20 [1280/5448 (23%)]\n",
            " Loss: 0.158977\n",
            "Epoch : 30 [1920/5448 (35%)]\n",
            " Loss: 0.009475\n",
            "Epoch : 40 [2560/5448 (47%)]\n",
            " Loss: 0.044941\n",
            "Epoch : 50 [3200/5448 (58%)]\n",
            " Loss: 0.007162\n",
            "Epoch : 60 [3840/5448 (70%)]\n",
            " Loss: 0.006386\n",
            "Epoch : 70 [4480/5448 (81%)]\n",
            " Loss: 0.019420\n",
            "Epoch : 80 [5120/5448 (93%)]\n",
            " Loss: 0.020713\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3483, Accuracy: 9626/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 552\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5512 (0%)]\n",
            " Loss: 0.048012\n",
            "Epoch : 10 [640/5512 (11%)]\n",
            " Loss: 0.124014\n",
            "Epoch : 20 [1280/5512 (23%)]\n",
            " Loss: 0.002459\n",
            "Epoch : 30 [1920/5512 (34%)]\n",
            " Loss: 0.105534\n",
            "Epoch : 40 [2560/5512 (46%)]\n",
            " Loss: 0.077733\n",
            "Epoch : 50 [3200/5512 (57%)]\n",
            " Loss: 0.073133\n",
            "Epoch : 60 [3840/5512 (69%)]\n",
            " Loss: 0.001189\n",
            "Epoch : 70 [4480/5512 (80%)]\n",
            " Loss: 0.017247\n",
            "Epoch : 80 [5120/5512 (92%)]\n",
            " Loss: 0.052061\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3671, Accuracy: 9627/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 488\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5576 (0%)]\n",
            " Loss: 0.026543\n",
            "Epoch : 10 [640/5576 (11%)]\n",
            " Loss: 0.000353\n",
            "Epoch : 20 [1280/5576 (23%)]\n",
            " Loss: 0.019207\n",
            "Epoch : 30 [1920/5576 (34%)]\n",
            " Loss: 0.040570\n",
            "Epoch : 40 [2560/5576 (45%)]\n",
            " Loss: 0.171762\n",
            "Epoch : 50 [3200/5576 (57%)]\n",
            " Loss: 0.000290\n",
            "Epoch : 60 [3840/5576 (68%)]\n",
            " Loss: 0.217581\n",
            "Epoch : 70 [4480/5576 (80%)]\n",
            " Loss: 0.010501\n",
            "Epoch : 80 [5120/5576 (91%)]\n",
            " Loss: 0.176971\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3856, Accuracy: 9580/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 424\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5640 (0%)]\n",
            " Loss: 0.006093\n",
            "Epoch : 10 [640/5640 (11%)]\n",
            " Loss: 0.132178\n",
            "Epoch : 20 [1280/5640 (22%)]\n",
            " Loss: 0.017615\n",
            "Epoch : 30 [1920/5640 (34%)]\n",
            " Loss: 0.029322\n",
            "Epoch : 40 [2560/5640 (45%)]\n",
            " Loss: 0.116576\n",
            "Epoch : 50 [3200/5640 (56%)]\n",
            " Loss: 0.018029\n",
            "Epoch : 60 [3840/5640 (67%)]\n",
            " Loss: 0.100907\n",
            "Epoch : 70 [4480/5640 (79%)]\n",
            " Loss: 0.017629\n",
            "Epoch : 80 [5120/5640 (90%)]\n",
            " Loss: 0.011437\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3363, Accuracy: 9625/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 360\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5704 (0%)]\n",
            " Loss: 0.014305\n",
            "Epoch : 10 [640/5704 (11%)]\n",
            " Loss: 0.003794\n",
            "Epoch : 20 [1280/5704 (22%)]\n",
            " Loss: 0.008467\n",
            "Epoch : 30 [1920/5704 (33%)]\n",
            " Loss: 0.024504\n",
            "Epoch : 40 [2560/5704 (44%)]\n",
            " Loss: 0.027042\n",
            "Epoch : 50 [3200/5704 (56%)]\n",
            " Loss: 0.021258\n",
            "Epoch : 60 [3840/5704 (67%)]\n",
            " Loss: 0.174064\n",
            "Epoch : 70 [4480/5704 (78%)]\n",
            " Loss: 0.000168\n",
            "Epoch : 80 [5120/5704 (89%)]\n",
            " Loss: 0.020872\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3912, Accuracy: 9582/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 296\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5768 (0%)]\n",
            " Loss: 0.126009\n",
            "Epoch : 10 [640/5768 (11%)]\n",
            " Loss: 0.008275\n",
            "Epoch : 20 [1280/5768 (22%)]\n",
            " Loss: 0.063152\n",
            "Epoch : 30 [1920/5768 (33%)]\n",
            " Loss: 0.004463\n",
            "Epoch : 40 [2560/5768 (44%)]\n",
            " Loss: 0.000413\n",
            "Epoch : 50 [3200/5768 (55%)]\n",
            " Loss: 0.077485\n",
            "Epoch : 60 [3840/5768 (66%)]\n",
            " Loss: 0.000156\n",
            "Epoch : 70 [4480/5768 (77%)]\n",
            " Loss: 0.052331\n",
            "Epoch : 80 [5120/5768 (88%)]\n",
            " Loss: 0.013855\n",
            "Epoch : 90 [720/5768 (99%)]\n",
            " Loss: 0.000047\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3700, Accuracy: 9590/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 232\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5832 (0%)]\n",
            " Loss: 0.001298\n",
            "Epoch : 10 [640/5832 (11%)]\n",
            " Loss: 0.007076\n",
            "Epoch : 20 [1280/5832 (22%)]\n",
            " Loss: 0.032771\n",
            "Epoch : 30 [1920/5832 (33%)]\n",
            " Loss: 0.040957\n",
            "Epoch : 40 [2560/5832 (43%)]\n",
            " Loss: 0.047878\n",
            "Epoch : 50 [3200/5832 (54%)]\n",
            " Loss: 0.005985\n",
            "Epoch : 60 [3840/5832 (65%)]\n",
            " Loss: 0.002769\n",
            "Epoch : 70 [4480/5832 (76%)]\n",
            " Loss: 0.000171\n",
            "Epoch : 80 [5120/5832 (87%)]\n",
            " Loss: 0.067733\n",
            "Epoch : 90 [5760/5832 (98%)]\n",
            " Loss: 0.002050\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3511, Accuracy: 9635/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 168\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5896 (0%)]\n",
            " Loss: 0.144696\n",
            "Epoch : 10 [640/5896 (11%)]\n",
            " Loss: 0.276332\n",
            "Epoch : 20 [1280/5896 (22%)]\n",
            " Loss: 0.014762\n",
            "Epoch : 30 [1920/5896 (32%)]\n",
            " Loss: 0.000073\n",
            "Epoch : 40 [2560/5896 (43%)]\n",
            " Loss: 0.043283\n",
            "Epoch : 50 [3200/5896 (54%)]\n",
            " Loss: 0.002017\n",
            "Epoch : 60 [3840/5896 (65%)]\n",
            " Loss: 0.105914\n",
            "Epoch : 70 [4480/5896 (75%)]\n",
            " Loss: 0.018294\n",
            "Epoch : 80 [5120/5896 (86%)]\n",
            " Loss: 0.002016\n",
            "Epoch : 90 [5760/5896 (97%)]\n",
            " Loss: 0.043804\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3379, Accuracy: 9594/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 104\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/5960 (0%)]\n",
            " Loss: 0.009592\n",
            "Epoch : 10 [640/5960 (11%)]\n",
            " Loss: 0.049536\n",
            "Epoch : 20 [1280/5960 (21%)]\n",
            " Loss: 0.000168\n",
            "Epoch : 30 [1920/5960 (32%)]\n",
            " Loss: 0.005851\n",
            "Epoch : 40 [2560/5960 (43%)]\n",
            " Loss: 0.032200\n",
            "Epoch : 50 [3200/5960 (53%)]\n",
            " Loss: 0.002945\n",
            "Epoch : 60 [3840/5960 (64%)]\n",
            " Loss: 0.168793\n",
            "Epoch : 70 [4480/5960 (74%)]\n",
            " Loss: 0.005323\n",
            "Epoch : 80 [5120/5960 (85%)]\n",
            " Loss: 0.006115\n",
            "Epoch : 90 [5760/5960 (96%)]\n",
            " Loss: 0.000586\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3054, Accuracy: 9633/10000 (96%)\n",
            "\n",
            "Using BatchBALD Acquiring technique for Batch Acquisition.\n",
            " Current size of the Pool Set: 40\n",
            "Training the Model on new Training Set\n",
            "Epoch : 0 [0/6024 (0%)]\n",
            " Loss: 0.007319\n",
            "Epoch : 10 [640/6024 (11%)]\n",
            " Loss: 0.007102\n",
            "Epoch : 20 [1280/6024 (21%)]\n",
            " Loss: 0.002391\n",
            "Epoch : 30 [1920/6024 (32%)]\n",
            " Loss: 0.000463\n",
            "Epoch : 40 [2560/6024 (42%)]\n",
            " Loss: 0.000011\n",
            "Epoch : 50 [3200/6024 (53%)]\n",
            " Loss: 0.016324\n",
            "Epoch : 60 [3840/6024 (63%)]\n",
            " Loss: 0.162573\n",
            "Epoch : 70 [4480/6024 (74%)]\n",
            " Loss: 0.006188\n",
            "Epoch : 80 [5120/6024 (84%)]\n",
            " Loss: 0.004642\n",
            "Epoch : 90 [5760/6024 (95%)]\n",
            " Loss: 0.128380\n",
            "Testing the Model on Test Set \n",
            "\n",
            "Average loss: 0.3147, Accuracy: 9629/10000 (96%)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}